/**
 * Composable –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ - –ø—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è VAD
 */

import { ref, onMounted, onUnmounted } from 'vue'
import { useSocket } from './useSocket.js'

// –ü—Ä–æ—Å—Ç–∞—è throttle —Ñ—É–Ω–∫—Ü–∏—è
const throttle = (func, limit) => {
  let inThrottle
  return function(...args) {
    if (!inThrottle) {
      func.apply(this, args)
      inThrottle = true
      setTimeout(() => inThrottle = false, limit)
    }
  }
}

// –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ (singleton)
const speakingPlayers = ref([])
const isListening = ref(false)
const vadEnabled = ref(true)

export const useVoiceActivity = () => {
  const { emit } = useSocket()
  
  // –õ–æ–∫–∞–ª—å–Ω—ã–µ refs
  const audioContext = ref(null)
  const analyser = ref(null)
  const microphone = ref(null)
  const dataArray = ref(null)
  const isDetecting = ref(false)
  
  /**
   * –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞
   */
  const initVoiceDetection = async () => {
    if (!vadEnabled.value || isListening.value) return
    
    try {
      console.log('üéôÔ∏è Initializing voice detection')
      
      // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        } 
      })
      
      // –°–æ–∑–¥–∞–µ–º –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç
      audioContext.value = new (window.AudioContext || window.webkitAudioContext)()
      analyser.value = audioContext.value.createAnalyser()
      microphone.value = audioContext.value.createMediaStreamSource(stream)
      
      // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
      analyser.value.fftSize = 256
      analyser.value.smoothingTimeConstant = 0.8
      
      const bufferLength = analyser.value.frequencyBinCount
      dataArray.value = new Uint8Array(bufferLength)
      
      // –ü–æ–¥–∫–ª—é—á–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω –∫ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—É
      microphone.value.connect(analyser.value)
      
      isListening.value = true
      startVAD()
      
      console.log('‚úÖ Voice detection initialized')
      
    } catch (error) {
      console.error('‚ùå Failed to initialize voice detection:', error)
      vadEnabled.value = false
    }
  }
  
  /**
   * –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –≥–æ–ª–æ—Å–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
   */
  const startVAD = () => {
    if (!analyser.value || !dataArray.value) return
    
    const detectVoice = () => {
      if (!isListening.value) return
      
      analyser.value.getByteFrequencyData(dataArray.value)
      
      // –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å –∑–≤—É–∫–∞
      const average = dataArray.value.reduce((sum, value) => sum + value, 0) / dataArray.value.length
      
      // –ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ä–µ—á–∏
      const threshold = 30
      const isSpeaking = average > threshold
      
      // –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏
      if (isSpeaking !== isDetecting.value) {
        isDetecting.value = isSpeaking
        throttledEmitVoiceActivity(isSpeaking)
      }
      
      // –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∞–Ω–∞–ª–∏–∑
      requestAnimationFrame(detectVoice)
    }
    
    detectVoice()
  }
  
  /**
   * Throttled –æ—Ç–ø—Ä–∞–≤–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
   */
  const throttledEmitVoiceActivity = throttle((isSpeaking) => {
    console.log(`üé§ Emitting voice activity: speaking=${isSpeaking}`)
    emit('voice-activity', { speaking: isSpeaking })
  }, 150)
  
  /**
   * –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –≥–æ–ª–æ—Å–∞
   */
  const stopVoiceDetection = () => {
    console.log('üéôÔ∏è Stopping voice detection')
    
    isListening.value = false
    isDetecting.value = false
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ —Ç—Ä–µ–∫–∏
    if (microphone.value && microphone.value.mediaStream) {
      microphone.value.mediaStream.getTracks().forEach(track => track.stop())
    }
    
    // –ó–∞–∫—Ä—ã–≤–∞–µ–º –∞—É–¥–∏–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    if (audioContext.value && audioContext.value.state !== 'closed') {
      audioContext.value.close()
    }
    
    // –û—á–∏—â–∞–µ–º refs
    audioContext.value = null
    analyser.value = null
    microphone.value = null
    dataArray.value = null
  }
  
  /**
   * –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ VAD
   */
  const toggleVAD = async () => {
    vadEnabled.value = !vadEnabled.value
    
    if (vadEnabled.value) {
      await initVoiceDetection()
    } else {
      stopVoiceDetection()
    }
  }
  
  /**
   * –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥—Ä—É–≥–∏—Ö –∏–≥—Ä–æ–∫–æ–≤
   */
  const handlePlayerVoiceActivity = (data) => {
    const { playerId, speaking } = data
    console.log(`üéØ handlePlayerVoiceActivity: playerId=${playerId}, speaking=${speaking}`)
    console.log(`üìã speakingPlayers before:`, speakingPlayers.value)
    
    if (speaking) {
      // –î–æ–±–∞–≤–ª—è–µ–º –∏–≥—Ä–æ–∫–∞ –≤ —Å–ø–∏—Å–æ–∫ –≥–æ–≤–æ—Ä—è—â–∏—Ö
      if (!speakingPlayers.value.includes(playerId)) {
        speakingPlayers.value.push(playerId)
        console.log(`‚ûï Added player ${playerId} to speakingPlayers`)
      }
    } else {
      // –£–±–∏—Ä–∞–µ–º –∏–≥—Ä–æ–∫–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ –≥–æ–≤–æ—Ä—è—â–∏—Ö
      const index = speakingPlayers.value.indexOf(playerId)
      if (index > -1) {
        speakingPlayers.value.splice(index, 1)
        console.log(`‚ûñ Removed player ${playerId} from speakingPlayers`)
      }
    }
    
    console.log(`üìã speakingPlayers after:`, speakingPlayers.value)
  }
  
  /**
   * –û—á–∏—Å—Ç–∫–∞ –≥–æ–≤–æ—Ä—è—â–∏—Ö –∏–≥—Ä–æ–∫–æ–≤
   */
  const clearSpeakingPlayers = () => {
    speakingPlayers.value = []
  }
  
  /**
   * –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
   */
  const checkMicrophonePermission = async () => {
    try {
      const result = await navigator.permissions.query({ name: 'microphone' })
      return result.state === 'granted'
    } catch (error) {
      console.warn('Cannot check microphone permission:', error)
      return false
    }
  }
  
  /**
   * –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ WebRTC
   */
  const isWebRTCSupported = () => {
    return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia)
  }
  
  /**
   * –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–µ
   */
  const getMicrophoneInfo = async () => {
    try {
      const devices = await navigator.mediaDevices.enumerateDevices()
      const microphones = devices.filter(device => device.kind === 'audioinput')
      
      return microphones.map(mic => ({
        id: mic.deviceId,
        label: mic.label || '–ú–∏–∫—Ä–æ—Ñ–æ–Ω',
        groupId: mic.groupId
      }))
    } catch (error) {
      console.error('Failed to get microphone info:', error)
      return []
    }
  }
  
  // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
  onMounted(async () => {
    if (vadEnabled.value && isWebRTCSupported()) {
      const hasPermission = await checkMicrophonePermission()
      if (hasPermission) {
        await initVoiceDetection()
      }
    }
  })
  
  // –û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏
  onUnmounted(() => {
    stopVoiceDetection()
  })
  
  return {
    // –°–æ—Å—Ç–æ—è–Ω–∏–µ
    speakingPlayers,
    isListening,
    vadEnabled,
    isDetecting,
    
    // –ú–µ—Ç–æ–¥—ã
    initVoiceDetection,
    stopVoiceDetection,
    toggleVAD,
    handlePlayerVoiceActivity,
    clearSpeakingPlayers,
    
    // –£—Ç–∏–ª–∏—Ç—ã
    checkMicrophonePermission,
    isWebRTCSupported,
    getMicrophoneInfo
  }
}

  /**
   * –ü—Ä–æ—Å—Ç–∞—è throttle —Ñ—É–Ω–∫—Ü–∏—è (—É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–Ω–∏–∑—É)
   */